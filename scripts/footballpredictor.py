# -*- coding: utf-8 -*-
"""FootballPredictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nLG2cflhsl3Lv5WrXcl3xFqOrj5G7jjM

# Train classifier to predict wins v.s (loss + draw)

A breakdown of the variables to train with:

* poss = possesion (% of passes attempted)
* xg   = expected goals
* touches = number of touches
* def 3rd = number of touches in def 3rd
* mid 3rd = similar to above
* att 3rd = similar to above
* att pen = similiar to above
* live = live-ball touches
* ast = assists
* xag = expected assisted goals
* xA = expected assists
* KP = key passes
* 1/3 = passes into final third
* ppa = passes into penalty area
* crspa = crosses into penalty area
* prgp = progressive/forward passes 
* npxg = non-penalty expected goals
* npxg/sh = same as above but per shot
* g-xg = goals minus expected goals
* npg-npxg = non pen goals minus non pen expected goals
* team = one hot team names 
* hours = closest hour of the day match was played in
* day = day of week match was played on
* opponent = one hot team names
* gf = goals for
* ga = goals against
* formation = one hot formations

"""

import pandas as pd
import xgboost as xgb
import numpy as np
from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score
from sklearn.ensemble import RandomForestClassifier
import seaborn as sns
import matplotlib.pyplot as plt

"""##config"""

nominal_vars = ['team','hours','day','opponent','formation', 'venue'] #might need to remove formation if can't get access to it for upcoming games!

train_vars_to_roll = ['poss','touches','def pen','def 3rd', 'mid 3rd', 'att 3rd', 'att pen', 'live',
                      'totdist','prgdist','ast','xag','xa','kp','1/3','ppa','crspa','prgp',
                      'gls','sh','sot','sot%','g/sh','g/sot','dist','fk','pk','pkatt','xg','npxg',
                      'npxg/sh','g-xg','np:g-xg','gf','ga'
                     ]


#FIXME in window variables for opossing team maybe? and other variables by doing a0l join?

"""## Plot inputs and make Corr Map

## Train model
"""

def change_dtypes(df):

    def fix_away_games(score):
        if score is np.nan: return np.nan
        # for 2 leg games, first leg score is given in brackets e.g. 1 (2)
        elif '(' in score: return int(score[0])
        else: return int(float(score))

    if 'date' in df.columns: df['date'] = pd.to_datetime(df['date'])
    if 'gf' in df.columns: 
        df['gf'] = df['gf'].apply(fix_away_games)
    if 'ga' in df.columns: 
        df['ga'] = df['ga'].apply(fix_away_games)

    return df

def create_time_features(df):
    if 'venue' in df.columns: df['venue'] = df['venue'].astype('category').cat.codes
    if 'time' in df.columns: df['hours'] = df['time'].str.replace(':.+','', regex=True).astype('int')
    if 'date' in df.columns: df['day'] = df['date'].dt.dayofweek
    if 'formation' in df.columns: df['formation'] = df['formation'].astype('category').cat.codes

    return df

#sometimes possesion info etc just wasn't filled in on the site. We'll try to impute from avgs of similar rows
def impute_nulls(df, impute=False):
    
    if impute:
        for col_name in train_vars_to_roll:
            df[col_name] = df[col_name].fillna(df.groupby(['team','year'])[col_name].transform('mean'))
    else:
        df = df.dropna(how='any')

    return df

class MissingDict(dict):
  __missing__ = lambda self, key:key

#some teams have different names in the Team and Opponent column
#for some reason I can't replace '-' with ' '... so have to brute force replace them :(
team_mapping = MissingDict(**{
    'Aston Villa':'Aston-Villa', 'Brighton': 'Brighton-and-Hove-Albion', 'Cardiff City': 'Cardiff-City',
    'Crystal Palace': 'Crystal-Palace', 'Huddersfield':'Huddersfield-Town', 'Leeds United':'Leeds-United',
    'Leicester City': 'Leicester-City', 'Manchester City': 'Manchester-City', 'Manchester Utd': 'Manchester-United',
    'Newcastle Utd': 'Newcastle-United', 'Norwich City': 'Norwich-City', "Nott'ham Forest": 'Nottingham-Forest',
    'Sheffield Utd': 'Sheffield-United', 'Stoke City':'Stoke-City', 'Swansea City':'Swansea-City',
    'Tottenham':'Tottenham-Hotspur', 'West Brom':'West-Bromwich-Albion', 'West Ham':'West-Ham-United', 'Wolves':'Wolverhampton-Wanderers',

    'Bayern Munich':'Bayern-Munich', 'Union Berlin':'Union-Berlin', 'RB Leipzig':'RB-Leipzig',
    'Bayer Leverkusen': 'Bayer-Leverkusen', 'Leverkusen':'Bayer-Leverkusen', 'Mainz 05':'Mainz-05', 'Eint Frankfurt':'Eintracht-Frankfurt',
    "M'Gladbach":'Monchengladbach', 'Köln':'Koln', 'Werder Bremen': 'Werder-Bremen', 'Schalke 04':'Schalke-04',
    'Hertha BSC':'Hertha-BSC', 'Greuther Fürth':'Greuther-Furth', 'Düsseldorf':'Dusseldorf',
    'Paderborn 07':'Paderborn-07', 'Hannover 96':'Hannover-96', 'Hamburger SV':'Hamburger-SV', 'Nürnberg':'Nurnberg',

    'Rayo Vallecano':'Rayo-Vallecano',  'Real Sociedad':'Real-Sociedad', 'Cádiz':'Cadiz',
    'Celta Vigo':'Celta-Vigo', 'Real Madrid':'Real-Madrid', 'Athletic Club':'Athletic-Club',
    'Almería':'Almeria', 'Atlético Madrid':'Atletico-Madrid', 'Betis':'Real-Betis',
    'Alavés':'Alaves','Leganés':'Leganes', 'Las Palmas':'Las-Palmas', 'Málaga':'Malaga',
    'La Coruña':'Deportivo-La-Coruna',

     'Clermont Foot':'Clermont-Foot', 'Paris S-G':'Paris-Saint-Germain', 'Saint-Étienne':'Saint-Etienne',
     'Nîmes':'Nimes',

     'Hellas Verona':'Hellas-Verona', 'Inter':'Internazionale'

})
   


  #merge opponent info
  #FIXME add in other primary leagues into map and filter

df1 = pd.read_csv("match_data_BundesLiga.csv", index_col=0)
df2 = pd.read_csv("match_data_EPL.csv", index_col=0)
df3 = pd.read_csv("match_data_LaLiga.csv", index_col=0)
df4 = pd.read_csv("match_data_Ligue1.csv", index_col=0)
df5 = pd.read_csv("match_data_SerieA.csv", index_col=0)

df = pd.concat([df1,df2,df3,df4,df5])

df = df.query(f"comp=='Premier League' or comp=='Bundesliga' or comp=='Serie A' or comp=='Ligue 1' or comp=='La Liga'")

df = df.dropna(how='all')
df = change_dtypes(df)
df = impute_nulls(df, impute=True)
df = create_time_features(df)
df['y_true'] = (df['result']=='W').astype('int8')
print(f'after cleaning, df has: {df.duplicated(keep=False).sum()} duplicate rows')

full_feature_set = set()

#add lagged features for last 5 days
lags = [1,2,3,4,5]
lag_vars = [f'lag_{lag}' for lag in lags]
lagged_dfs = []
for group in df.groupby(['team','year'], group_keys=False):
    gr = group[-1].sort_values(['date'])
    for lag in lags:
        gr[f'lag_{lag}'] = gr['y_true'].shift(lag)
        full_feature_set.add(f'lag_{lag}')
    lagged_dfs.append(gr)
df = pd.concat(lagged_dfs, ignore_index=True) 



#add rolled mean features 
rolled_dfs = []
n_days = 5
for group in df.groupby(['team','year'], group_keys=False):
    gr = group[-1].sort_values(['date'])
    for var in train_vars_to_roll:
        #gr[rolled_train_vars[var]] = gr[var].rolling(n_days, closed='left', win_type='exponential').mean(tau=0.5) #closed='left' does not work with exp window
        modified_var = var+'_rolling_avg'
        gr[modified_var] = gr[var].rolling(n_days, closed='left').mean()
        full_feature_set.add(modified_var)
    rolled_dfs.append(gr)
df = pd.concat(rolled_dfs, ignore_index=True)



##add rolled median features 
rolled_dfs = []
n_days = 5
for group in df.groupby(['team','year'], group_keys=False):
    gr = group[-1].sort_values(['date'])
    for var in train_vars_to_roll:
        modified_var = var+'_rolling_med'
        gr[modified_var] = gr[var].rolling(n_days, closed="left").median() #probs a way to do this without a dict but oh well
        full_feature_set.add(modified_var)
    rolled_dfs.append(gr)
df = pd.concat(rolled_dfs, ignore_index=True)



#add expanded mean features
expanded_dfs = []
for group in df.groupby(['team','year'], group_keys=False):
    gr = group[-1].sort_values(['date'])
    for var in train_vars_to_roll:
        modified_var = var+'_expanded'
        gr[modified_var] = gr[var].expanding().mean()
        full_feature_set.add(modified_var)
    expanded_dfs.append(gr)
df = pd.concat(expanded_dfs, ignore_index=True)



#drop any row with a null 
df = df.dropna(how='any')
df = df.sort_values(['date'])
df.index = range(df.shape[0])

#FIXME check i dropped repeated info e.g. date

#FIXME check why we dont have exact duplicates after merging

#FIXME check if it is actually doing what you expect!! i.e. check it against actual stats on the website to see if the games matched up properly

#FIXME: make encoding the same! for all encoded features!!! e.g. dats, years - had to drop them atm. Add them back into features

print(df.shape)
df['opponent'] = df['opponent'].map(team_mapping)
df = df.merge(df[list(full_feature_set)+['date','opponent','venue']], 
              left_on=["date", "team"], 
              right_on=["date", "opponent"], 
              suffixes=("","_opp"),
              how='inner'
              )


# HAVE TO BE CAREFUL - pandas might encode opponent and team differently in two different columns. So e.g. Arsenal = 0 in team but =10 in opponent! so kpeeing as strings for line above, then converting for line below
#df = encode_teams(df, team_mapping)


print(df.shape)
df = df.drop_duplicates() 
print(df.shape)

#train/test split
final_train_vars = list(full_feature_set) + [v+'_opp' for v in list(full_feature_set)]
print(f'training with {len(final_train_vars)} variables')

x_train = df[df['date']<'2022-08-01'][final_train_vars] 
y_train = df[df['date']<'2022-08-01']['y_true'] 

x_test  = df[df['date']>'2022-08-01'][final_train_vars] 
y_test  = df[df['date']>'2022-08-01']['y_true']

#train GBDT  
clf = xgb.XGBClassifier(objective='binary:logistic', n_estimators=100, 
                        eta=0.05, max_depth=3)
#Train RF
#clf = RandomForestClassifier()
                                 
clf.fit(x_train,y_train)

#predict probs and classes (argmax)
y_pred_train = clf.predict_proba(x_train)[:,1:].ravel() 
y_pred_train_class = clf.predict(x_train) 
y_pred_test = clf.predict_proba(x_test)[:,1:].ravel()
y_pred_test_class = clf.predict(x_test)

#baseline_roc = roc_auc_score(y_test, x_test['venue'])
#print(f'baseline roc_score {baseline_roc}')
print(f'train roc_score: {roc_auc_score(y_train, y_pred_train)}')
print(f'test roc_score: {roc_auc_score(y_test, y_pred_test)}')

print()

#baseline_acc = accuracy_score(y_test, x_test['venue'], )
#print(f'baseline accuracy {baseline_acc}')
print(f'train accuracy: {accuracy_score(y_train, y_pred_train_class)}')
print(f'test accuracy: {accuracy_score(y_test, y_pred_test_class)}')

""" ## Make some performance plots"""

#Plot the output score

pass

#ROCs
loss_eff_train, win_eff_train, _ = roc_curve(y_train, y_pred_train)
loss_eff_test, win_eff_test, _ = roc_curve(y_test, y_pred_test)

fig = plt.figure(1)
axes = fig.gca()
axes.plot(loss_eff_train, win_eff_train, color='red', label='Train set')
axes.plot(loss_eff_test, win_eff_test, color='royalblue', label='Test set')

axes.plot(np.linspace(0,1,100),np.linspace(0,1,100), linestyle="--", color='black', zorder=0, label="Random classifier")
axes.set_xlabel('False positive rate', ha='right', x=1, size=13)
axes.set_xlim((0,1))
axes.set_ylabel('True positive rate', ha='right', y=1, size=13)
axes.set_ylim((0,1))
axes.legend(bbox_to_anchor=(0.97,0.28))
axes.grid(True, 'major', linestyle='solid', color='grey', alpha=0.5)

#confusion matrix
trues_preds_test = pd.DataFrame({'actual':y_test, 'prediction':y_pred_test_class})
c_matrix = pd.crosstab(index=trues_preds_test['actual'], columns=trues_preds_test['prediction'], normalize='columns')
fig = sns.heatmap(c_matrix, vmin=0, vmax=1, annot=True, cmap='viridis')

#make some SHAP plots
